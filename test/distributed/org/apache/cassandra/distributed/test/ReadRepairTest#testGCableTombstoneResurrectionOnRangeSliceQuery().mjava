    /**
     * Range queries before CASSANDRA-11427 will trigger read repairs for puregable tombstones on hosts that already
     * compacted given tombstones. This will result in constant transfer and compaction actions sourced by few nodes
     * seeding purgeable tombstones and triggered e.g. by periodical jobs scanning data range wise.
     * <p>
     * See CASSANDRA-11427.
     * <p>
     * Migrated from Python dtest read_repair_test.py:TestReadRepair.test_gcable_tombstone_resurrection_on_range_slice_query()
     */
    @Test
    public void testGCableTombstoneResurrectionOnRangeSliceQuery() throws Throwable
    {
        try (Cluster cluster = init(Cluster.create(2)))
        {
            cluster.schemaChange(withKeyspace("CREATE TABLE %s.t (k int, c int, PRIMARY KEY(k, c)) " +
                                              "WITH gc_grace_seconds=0 AND compaction = " +
                                              "{'class': 'SizeTieredCompactionStrategy', 'enabled': 'false'}"));

            ICoordinator coordinator = cluster.coordinator(1);

            // insert some data
            coordinator.execute(withKeyspace("INSERT INTO %s.t(k, c) VALUES (0, 0)"), ALL);
            coordinator.execute(withKeyspace("INSERT INTO %s.t(k, c) VALUES (1, 1)"), ALL);

            // create partition tombstones in all nodes for both existent and not existent partitions
            coordinator.execute(withKeyspace("DELETE FROM %s.t WHERE k=0"), ALL); // exists
            coordinator.execute(withKeyspace("DELETE FROM %s.t WHERE k=2"), ALL); // doesn't exist

            // create row tombstones in all nodes for both existent and not existent rows
            coordinator.execute(withKeyspace("DELETE FROM %s.t WHERE k=1 AND c=1"), ALL); // exists
            coordinator.execute(withKeyspace("DELETE FROM %s.t WHERE k=3 AND c=1"), ALL); // doesn't exist

            // flush single sstable with tombstones
            cluster.get(1).flush(KEYSPACE);
            cluster.get(2).flush(KEYSPACE);

            // purge tombstones from node2 with compaction (gc_grace_seconds=0)
            cluster.get(2).forceCompact(KEYSPACE, "t");

            // run an unrestricted range query verifying that it doesn't trigger read repair
            coordinator.execute(withKeyspace("SELECT * FROM %s.t"), ALL);
            long requests = ReadRepairTester.readRepairRequestsCount(cluster.get(1), "t");
            assertEquals("No read repair requests were expected, found " + requests, 0, requests);
        }
    }

