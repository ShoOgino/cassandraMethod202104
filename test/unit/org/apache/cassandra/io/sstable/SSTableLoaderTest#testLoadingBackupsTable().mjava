    @Test
    public void testLoadingBackupsTable() throws Exception
    {
        File dataDir = dataDir(CF_BACKUPS);
        TableMetadata metadata = Schema.instance.getTableMetadata(KEYSPACE1, CF_BACKUPS);

        try (CQLSSTableWriter writer = CQLSSTableWriter.builder()
                                                       .inDirectory(dataDir)
                                                       .forTable(String.format(schema, KEYSPACE1, CF_BACKUPS))
                                                       .using(String.format(query, KEYSPACE1, CF_BACKUPS))
                                                       .build())
        {
            writer.addRow("key", "col1", "100");
        }

        ColumnFamilyStore cfs = Keyspace.open(KEYSPACE1).getColumnFamilyStore(CF_BACKUPS);
        cfs.forceBlockingFlush(); // wait for sstables to be on disk else we won't be able to stream them

        final CountDownLatch latch = new CountDownLatch(1);
        SSTableLoader loader = new SSTableLoader(dataDir, new TestClient(), new OutputHandler.SystemOutput(false, false));
        loader.stream(Collections.emptySet(), completionStreamListener(latch)).get();

        List<FilteredPartition> partitions = Util.getAll(Util.cmd(cfs).build());

        assertEquals(1, partitions.size());
        assertEquals("key", AsciiType.instance.getString(partitions.get(0).partitionKey().getKey()));
        assert metadata != null;
        assertEquals(ByteBufferUtil.bytes("100"), partitions.get(0).getRow(Clustering.make(ByteBufferUtil.bytes("col1")))
                                                            .getCell(metadata.getColumn(ByteBufferUtil.bytes("val")))
                                                            .buffer());

        // The stream future is signalled when the work is complete but before releasing references. Wait for release
        // before cleanup (CASSANDRA-10118).
        latch.await();
    }

